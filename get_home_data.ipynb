{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from selenium import webdriver  \n",
    "from selenium.common.exceptions import NoSuchElementException  \n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "from pyvirtualdisplay import Display #use linuxbrew to install chromedriver if you want to do this on AWS instead of your local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use the Portland Maps API to get all homes sold in Portland over a two year span. https://www.portlandmaps.com/development/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/psf/requests/issues/3829\n",
    "# alternate not tried: https://stackoverflow.com/questions/48391750/disable-python-requests-ssl-validation-for-an-imported-module \n",
    "# probably better: https://stackoverflow.com/questions/39356413/how-to-add-a-custom-ca-root-certificate-to-the-ca-store-used-by-pip-in-windows/52961564#52961564 \n",
    "# https://curl.haxx.se/docs/sslcerts.html\n",
    "class WrappedSession(requests.Session):\n",
    "    \"\"\"A wrapper for requests.Session to override 'verify' property, ignoring REQUESTS_CA_BUNDLE environment variable.\n",
    "\n",
    "    This is a workaround for https://github.com/kennethreitz/requests/issues/3829 (will be fixed in requests 3.0.0)\n",
    "    \"\"\"\n",
    "    def merge_environment_settings(self, url, proxies, stream, verify, *args, **kwargs):\n",
    "        if self.verify is False:\n",
    "            verify = False\n",
    "\n",
    "        return super(WrappedSession, self).merge_environment_settings(url, proxies, stream, verify, *args, **kwargs)\n",
    "    \n",
    "\n",
    "\n",
    "WrappedSession(requests.get('https://www.google.com',verify=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35009\n"
     ]
    }
   ],
   "source": [
    "#get all houses sold since between 7/1/16 and 6/30/17 from Portland Maps\n",
    "addresses = []\n",
    "\n",
    "\n",
    "kwargs = {'api_key': '###',\n",
    "    'sqft_larger': '1',\n",
    "    'sold_after': '07/01/2016',\n",
    "    'sold_before': '06/30/2017',\n",
    "    'page':'1',\n",
    "    'format': 'json'\n",
    "    }\n",
    "    \n",
    "u = 'http://www.portlandmaps.com/api/assessor'\n",
    "request = requests.get(u, params=kwargs)\n",
    "js = json.loads(request.text)\n",
    "\n",
    "print(js['total'])\n",
    "    \n",
    "    \n",
    "for i in range(len(js['results'])):\n",
    "    if (js['results'][i]['address']):\n",
    "        addresses.append(js['results'][i])\n",
    "            \n",
    "if int(js['total']) > 1000:\n",
    "    pages = int(js['total'])//1000\n",
    "    \n",
    "    for i in range(2,pages+2):\n",
    "        kwargs = {'api_key': '###',\n",
    "        'sqft_larger': '1',\n",
    "        'sold_after': '07/01/2016',\n",
    "        'sold_before': '06/30/2017',\n",
    "        'page': i,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    \n",
    "        u = 'https://www.portlandmaps.com/api/assessor'\n",
    "        request = requests.get(u, params=kwargs)\n",
    "        js = json.loads(request.text)\n",
    "        \n",
    "        for i in range(len(js['results'])):\n",
    "            if (js['results'][i]['address']):\n",
    "                addresses.append(js['results'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12965\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>legal_description</th>\n",
       "      <th>market_value</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>owner</th>\n",
       "      <th>property_id</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01100 SW PALATINE HILL RD</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>45.44406</td>\n",
       "      <td>-122.66709</td>\n",
       "      <td>PALATINE HILL, LOT 45 TL 1000</td>\n",
       "      <td>1299050.0</td>\n",
       "      <td>MULT CO RIVERDALE AREA</td>\n",
       "      <td>VENTURA,KATHLEEN L &amp; O'NEILL,JAMES</td>\n",
       "      <td>R232835</td>\n",
       "      <td>2017-06-07</td>\n",
       "      <td>1250000</td>\n",
       "      <td>3952</td>\n",
       "      <td>1943</td>\n",
       "      <td>97219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01115 SW COMUS ST</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>45.44701</td>\n",
       "      <td>-122.66653</td>\n",
       "      <td>PALATINE HILL 3, BLOCK 106, LOT 15&amp;16</td>\n",
       "      <td>657150.0</td>\n",
       "      <td>MULT CO RIVERDALE AREA</td>\n",
       "      <td>CARLSON,JORDAN &amp; CARLSON,ALISHA</td>\n",
       "      <td>R232939</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>650000</td>\n",
       "      <td>1533</td>\n",
       "      <td>1968</td>\n",
       "      <td>97219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01250 SW RADCLIFFE RD</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>45.45065</td>\n",
       "      <td>-122.66573</td>\n",
       "      <td>SECTION 27 1S 1E, TL 2500 0.36 ACRES</td>\n",
       "      <td>837050.0</td>\n",
       "      <td>MULT CO RIVERDALE AREA</td>\n",
       "      <td>BEST,DUSTIN &amp; BEST,KRISTEN J</td>\n",
       "      <td>R330649</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>880000</td>\n",
       "      <td>2832</td>\n",
       "      <td>1967</td>\n",
       "      <td>97219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01510 SW BUDDINGTON ST</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>45.44247</td>\n",
       "      <td>-122.66318</td>\n",
       "      <td>SECTION 34 1S 1E, TL 1400 1.00 ACRES</td>\n",
       "      <td>2914590.0</td>\n",
       "      <td>MULT CO RIVERDALE AREA</td>\n",
       "      <td>COOKS,BRANDIN</td>\n",
       "      <td>R331686</td>\n",
       "      <td>2016-12-13</td>\n",
       "      <td>2850000</td>\n",
       "      <td>8189</td>\n",
       "      <td>2012</td>\n",
       "      <td>97219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01551 SW MILITARY RD</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>45.44107</td>\n",
       "      <td>-122.66245</td>\n",
       "      <td>ABERNETHY HTS, LOT 42 TL 500</td>\n",
       "      <td>1211680.0</td>\n",
       "      <td>MULT CO RIVERDALE AREA</td>\n",
       "      <td>KARL SCHULZ MANAGEMENT GROUP LLC</td>\n",
       "      <td>R100303</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>880000</td>\n",
       "      <td>3275</td>\n",
       "      <td>1985</td>\n",
       "      <td>97219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     address      city  latitude  longitude  \\\n",
       "0  01100 SW PALATINE HILL RD  PORTLAND  45.44406 -122.66709   \n",
       "1          01115 SW COMUS ST  PORTLAND  45.44701 -122.66653   \n",
       "2      01250 SW RADCLIFFE RD  PORTLAND  45.45065 -122.66573   \n",
       "3     01510 SW BUDDINGTON ST  PORTLAND  45.44247 -122.66318   \n",
       "4       01551 SW MILITARY RD  PORTLAND  45.44107 -122.66245   \n",
       "\n",
       "                       legal_description  market_value  \\\n",
       "0          PALATINE HILL, LOT 45 TL 1000     1299050.0   \n",
       "1  PALATINE HILL 3, BLOCK 106, LOT 15&16      657150.0   \n",
       "2   SECTION 27 1S 1E, TL 2500 0.36 ACRES      837050.0   \n",
       "3   SECTION 34 1S 1E, TL 1400 1.00 ACRES     2914590.0   \n",
       "4           ABERNETHY HTS, LOT 42 TL 500     1211680.0   \n",
       "\n",
       "             neighborhood                               owner property_id  \\\n",
       "0  MULT CO RIVERDALE AREA  VENTURA,KATHLEEN L & O'NEILL,JAMES     R232835   \n",
       "1  MULT CO RIVERDALE AREA     CARLSON,JORDAN & CARLSON,ALISHA     R232939   \n",
       "2  MULT CO RIVERDALE AREA        BEST,DUSTIN & BEST,KRISTEN J     R330649   \n",
       "3  MULT CO RIVERDALE AREA                       COOKS,BRANDIN     R331686   \n",
       "4  MULT CO RIVERDALE AREA    KARL SCHULZ MANAGEMENT GROUP LLC     R100303   \n",
       "\n",
       "    sale_date  sale_price  square_feet  year_built  zip_code  \n",
       "0  2017-06-07     1250000         3952        1943   97219.0  \n",
       "1  2016-09-13      650000         1533        1968   97219.0  \n",
       "2  2016-08-24      880000         2832        1967   97219.0  \n",
       "3  2016-12-13     2850000         8189        2012   97219.0  \n",
       "4  2017-06-20      880000         3275        1985   97219.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.DataFrame(addresses)\n",
    "addresses = addresses[['address', 'city', 'latitude', 'longitude', 'legal_description', 'market_value', 'neighborhood', 'owner', 'property_id', 'sale_date', 'sale_price', 'square_feet', 'year_built', 'zip_code']]\n",
    "addresses = addresses[addresses['city'] == 'PORTLAND']\n",
    "addresses = addresses[addresses['neighborhood'] != 'HAYDEN ISLAND NEIGHBORHOOD NETWORK'] #get rid of floating homes\n",
    "addresses.reset_index(drop=True, inplace=True)\n",
    "print(len(addresses))\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll get the Portland Maps API details on each of the homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <Response [200]>\n",
      "1 <Response [200]>\n",
      "2 <Response [200]>\n",
      "3 <Response [200]>\n",
      "4 <Response [200]>\n",
      "5 <Response [200]>\n",
      "6 <Response [200]>\n",
      "7 <Response [200]>\n",
      "8 <Response [200]>\n",
      "9 <Response [200]>\n",
      "10 <Response [200]>\n",
      "11 <Response [200]>\n",
      "12 <Response [200]>\n",
      "13 <Response [200]>\n",
      "14 <Response [200]>\n",
      "15 <Response [200]>\n",
      "16 <Response [200]>\n",
      "17 <Response [200]>\n",
      "18 <Response [200]>\n",
      "19 <Response [200]>\n",
      "20 <Response [200]>\n",
      "21 <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#get full Portlandmaps detail of each of the above properties\n",
    "\n",
    "count = 1\n",
    "for i in range(len(addresses)):\n",
    "    kwargs = {'api_key': '###',\n",
    "    'detail_type': 'assessor',\n",
    "    'sections': '*',\n",
    "    'detail_id': addresses['property_id'][i],\n",
    "    'format': 'json'\n",
    "    }\n",
    "\n",
    "    u = 'https://www.portlandmaps.com/api/detail'\n",
    "    request = requests.get(u, params=kwargs)\n",
    "    if request.status_code == 429:\n",
    "        break\n",
    "    \n",
    "    if count % 150 == 0:\n",
    "        count = 1\n",
    "        time.sleep(600)\n",
    "    else:    \n",
    "        count = count + 1\n",
    "        time.sleep(2)\n",
    "    \n",
    "    if count % 10 == 0:\n",
    "        addresses.to_pickle('home_results.pkl')\n",
    "        \n",
    "    print(i,request)\n",
    "    js = json.loads(request.text)\n",
    "    try:\n",
    "        addresses.set_value(i, 'prop_tax_yr_of_sale', js['tax ' 'history'][1]['property_tax'])\n",
    "        addresses.set_value(i, 'lot_size', js['general']['total_land_area_sqft'])\n",
    "        addresses.set_value(i, 'type', js['improvements']['building_class'])\n",
    "        addresses.set_value(i, 'plumbing', js['improvements']['plumbing'])\n",
    "        addresses.set_value(i, 'description',js['improvements']['improvement_type'])\n",
    "        addresses.set_value(i, 'main_sqft', js['improvements']['details'][0]['area_sq_ft'])\n",
    "        addresses.set_value(i, 'segments', js['improvements']['number_of_segments'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the Zillow API to get more details on each of the homes. You need to make two API calls (ugh!) -  one to get the Zillow ID, and one to get the home details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#zillow keys\n",
    "#get a lot of keys because zillow has a 1000 call per day per key limit\n",
    "\n",
    "keys1 = ['###', '###', '###']\n",
    "\n",
    "keys2 = ['###', '###', '###']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(addresses)):\n",
    "    \n",
    "    if i & 1000 == 0: #API limits\n",
    "        count = count + 1\n",
    "        key = keys1[count]\n",
    "        \n",
    "    print(i, key)\n",
    "\n",
    "    kwargs = {'zws-id': key,\n",
    "        'address': addresses['address'][i],\n",
    "        'citystatezip': str(addresses['city'][i]) + ' OR ' + str(addresses['zip_code'][i])\n",
    "        }\n",
    "\n",
    "    u = 'http://www.zillow.com/webservice/GetDeepSearchResults.htm'\n",
    "    request = requests.get(u, params=kwargs)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        soup = BeautifulSoup(request.text,'html.parser')\n",
    "  \n",
    "        addresses.set_value(i, 'zillow_id',  soup.find_all('zpid')[0].text)\n",
    "        addresses.set_value(i, 'zillow_finished_sqft', soup.find_all('finishedsqft')[0].text)\n",
    "        addresses.set_value(i,'zillow_bedrooms', soup.find_all('bedrooms')[0].text)\n",
    "\n",
    "    except:\n",
    "        continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use this Zillow API to get school and realtor info\n",
    "\n",
    "count = 0\n",
    "for i in range(len(addresses)):\n",
    "    \n",
    "    if i & 1000 == 0: #API limits\n",
    "        count = count + 1\n",
    "        key = keys2[count]\n",
    "        \n",
    "    print(count, key)\n",
    "    \n",
    "    try:\n",
    "        zillow_id = int(addresses['zillow_id'][i])\n",
    "        count = count + 1\n",
    "        \n",
    "        kwargs = {'zws-id': key,\n",
    "        'zpid': zillow_id\n",
    "        }\n",
    "\n",
    "        u = 'http://www.zillow.com/webservice/GetUpdatedPropertyDetails.htm'\n",
    "        request = requests.get(u, params=kwargs)       \n",
    "        time.sleep(2)       \n",
    "        print(i,request, count)\n",
    "        soup = BeautifulSoup(request.text,'html.parser')\n",
    "        request = request.text\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "    try:\n",
    "        addresses.set_value(i, 'numrooms',  soup.find_all('numrooms')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'roof',  soup.find_all('roof')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'exteriormaterial',  soup.find_all('exteriormaterial')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'parkingtype',  soup.find_all('parkingtype')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'coveredparkingspaces',  soup.find_all('coveredparkingspaces')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'heatingsources',  soup.find_all('heatingsources')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'heatingsystem',  soup.find_all('heatingsystem')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'coolingsystem',  soup.find_all('coolingsystem')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'appliances',  soup.find_all('appliances')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'floorcovering',  soup.find_all('floorcovering')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'architecture',  soup.find_all('architecture')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'homedescription',  soup.find_all('homedescription')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'elementaryschool',  soup.find_all('elementaryschool')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'middleschool',  soup.find_all('middleschool')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        addresses.set_value(i, 'highschool',  soup.find_all('highschool')[0].text)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addresses.to_pickle('zillow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use need to get Redfin URLS of the houses in order to later download photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(addresses)):\n",
    "    if i % 100 == 0: #reload your browser once in a while\n",
    "        chromedriver = \"/usr/local/bin/chromedriver\"\n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "#        display = Display(visible=0, size=(1300, 1080)) #use these lines for AWS instead of local\n",
    "#        display.start()\n",
    "#        chromedriver = \"/home/ubuntu/.linuxbrew/bin/chromedriver\"\n",
    "#        driver = webdriver.Chrome(chromedriver)\n",
    "#        driver.set_window_size(1300, 1080)\n",
    "    try:\n",
    "        url = 'https://images.google.com/'\n",
    "#        driver.get(\"https://images.google.com/\") #use this for AWS instead of local\n",
    "        driver.get(url)\n",
    "\n",
    "        search = driver.find_element_by_xpath('//*[@id=\"lst-ib\"]')\n",
    "\n",
    "        address = addresses['address'][i] + ' Portland OR Redfin'\n",
    "\n",
    "        search.send_keys(address)\n",
    "\n",
    "        search.send_keys(Keys.RETURN)  # XXX: problem here.\n",
    "\n",
    "        pic = driver.find_element_by_xpath(\"//*[@id='rg_s']/div[1]/a/img\")\n",
    "\n",
    "        pic.click()\n",
    "        time.sleep(5)\n",
    "    \n",
    "        download_pic = driver.find_element_by_xpath(\"//*[@id='irc_cc']/div[2]/div[1]/div[2]/div[2]/a/img\")\n",
    "        time.sleep(2.5)\n",
    "    \n",
    "        src = download_pic.get_attribute('src')\n",
    "        print(i, src)\n",
    "    \n",
    "        addresses.set_value(i, 'url', src)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if (i-1)%100 == 0:\n",
    "        driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addresses.to_pickle('zillow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, get the photos. You need to hide your user agent from Redfin because they don't let you scrape directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#you must hide user agent from redfin!\n",
    "for i in range(0,len(addresses)):\n",
    "    link = addresses['url'][i]\n",
    "    print(link)\n",
    "    filename = 'pics/'+str(i)+'.png'\n",
    "    if 'https://ssl.cdn-redfin.com' in addresses['url'][i]:\n",
    "        !curl {link} -s -H 'Pragma: no-cache' -H 'Accept-Encoding: gzip, deflate, br' -H 'Accept-Language: en-US,en;q=0.8' -H 'Upgrade-Insecure-Requests: 1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36' -H 'Content-Type:application/x-www-form-urlencoded' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8' -H 'Cache-Control: no-cache'  -H 'Connection: keep-alive' --compressed > {filename}\n",
    "    else:\n",
    "        !curl {link} > {filename}\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if any files got messed up, try again:\n",
    "\n",
    "#for files that don't exist:\n",
    "for i in range(0,len(addresses)):\n",
    "    link = addresses['url'][i]\n",
    "    print(link)\n",
    "    filename = 'pics/'+str(i)+'.png'\n",
    "    if not os.path.exists(filename):\n",
    "        if 'https://ssl.cdn-redfin.com' in link:\n",
    "            !curl {link} -s -H 'Pragma: no-cache' -H 'Accept-Encoding: gzip, deflate, br' -H 'Accept-Language: en-US,en;q=0.8' -H 'Upgrade-Insecure-Requests: 1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36' -H 'Content-Type:application/x-www-form-urlencoded' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8' -H 'Cache-Control: no-cache'  -H 'Connection: keep-alive' --compressed > {filename}\n",
    "        else:\n",
    "            urllib.request.urlretrieve(link, filename)\n",
    "    time.sleep(2)\n",
    "\n",
    "#for files that didnt download correctly:\n",
    "for i in range(0,len(addresses)):\n",
    "    link = addresses['url'][i]\n",
    "    print(link)\n",
    "    filename = 'pics/'+str(i)+'.png'\n",
    "    if os.path.getsize(filename) < 500 :\n",
    "        if 'https://ssl.cdn-redfin.com' in link:\n",
    "            !curl {link} -s -H 'Pragma: no-cache' -H 'Accept-Encoding: gzip, deflate, br' -H 'Accept-Language: en-US,en;q=0.8' -H 'Upgrade-Insecure-Requests: 1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36' -H 'Content-Type:application/x-www-form-urlencoded' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8' -H 'Cache-Control: no-cache'  -H 'Connection: keep-alive' --compressed > {filename}\n",
    "        else:\n",
    "            urllib.request.urlretrieve(link, filename)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are any files still messed up? If so, delete those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(addresses)):\n",
    "    filename = 'pics/'+str(i)+'.png'\n",
    "    if os.path.getsize(filename) < 500 or if not os.path.exists(filename):\n",
    "        indices.append(i)\n",
    "addresses = addresses.drop(addresses.index[indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addresses.to_pickle('year2/home_results.pkl')\n",
    "addresses.to_csv('year2/home_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
